<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Work | Daniel Severo</title>
    <link>/blog/</link>
      <atom:link href="/blog/index.xml" rel="self" type="application/rss+xml" />
    <description>Work</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 12 Dec 2019 19:37:27 -0300</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Work</title>
      <link>/blog/</link>
    </image>
    
    <item>
      <title>Learning From Data, Problem 1.7</title>
      <link>/blog/lfd-p17/</link>
      <pubDate>Thu, 12 Dec 2019 19:37:27 -0300</pubDate>
      <guid>/blog/lfd-p17/</guid>
      <description>&lt;p&gt;This post is a solution to the problem taken from &lt;a href=&#34;http://www.amlbook.com&#34; target=&#34;_blank&#34;&gt;Abu-Mostafa, Yaser S., Malik Magdon-Ismail, and Hsuan-Tien Lin. &lt;strong&gt;Learning from data.&lt;/strong&gt; Vol. 4. New York, NY, USA:: AMLBook, 2012.&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Quoted text refers to the original problem statement, verbatim.&lt;/p&gt;

&lt;p&gt;For more solutions, see &lt;a href=&#34;/blog&#34;&gt;dsevero.com/blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Consider leaving a &lt;span style=&#34;text-shadow: none;&#34;&gt;&lt;a class=&#34;github-button&#34; href=&#34;https://github.com/dsevero/dsevero.com&#34; data-icon=&#34;octicon-star&#34; data-size=&#34;small&#34; data-show-count=&#34;true&#34; aria-label=&#34;Star this on GitHub&#34;&gt;Star&lt;/a&gt;&lt;script async defer src=&#34;https://buttons.github.io/buttons.js&#34;&gt;&lt;/script&gt;&lt;/span&gt; if this helps you.&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;A sample of heads and tails is created by tossing a coin a number of times independently. Assume we have a number of coins that generate different samples independently. For a given coin, let the probability of heads (probability of error) be $\mu$. The probability of obtaining $k$ heads in $N$ tosses of this coin is given by the binomial distribution:
$$ P\left[ k \mid N, \mu \right] = {N\choose k} \mu^k \left(1 - \mu\right)^{N-k}$$
Remember that the training error $\nu$ is $\frac{k}{N}$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The learning model used in this chapter is the following: assume you have a $N$ datapoints sampled independently from some unkown distribution $\mathbf{x}_n \sim P$, targets $y_n = f(\mathbf{x_n})$ and a set of hypotheses (e.g. machine learning models) $h \in \mathcal{H}$ of size $\mid \mathcal{H} \mid = M$. A coin flipping experiment is used to draw conclusions on the accuracy of binary classifiers. The $n$-th flip of a coin is the evaluation of some hypothesis $h$ on point $(\mathbf{x}_n, y_n)$. Heads (numerically, 1) represents an error $h(\mathbf{x}_n) \neq y_n$, while tails is a successful prediction. In the case of $M$ coins, we have $M$ hypotheses and $NM$ data points $(x_{m,n}, y_{m,n})$&lt;/p&gt;

&lt;p&gt;The objective of this problem is to show that, given a large enough set of hypotheses $\mathcal{H}$, the probability of obtaining low training error on at least one $h \in \mathcal{H}$ is high if the data is i.i.d. Therefore, we should be careful when evaluating models even if we have followed the standard train, test and validation split procedure.&lt;/p&gt;

&lt;p&gt;How does this translate to practice? Say you have a training dataset $\mathcal{D}$ and $M$ models $h_m \in \mathcal{H}$ that you wish to evaluate. You sample (with replacement) $N$ points $\mathbf{x}_{m,n} \in \mathcal{D}$ (e.g. mini-batch training) for each $h_m$ (i.e. a total of $NM$ points). What is the probability that at least one hypothesis will have zero in-sample error?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;(a) Assume the sample size $(N)$ is $10$. If all the coins have $\mu = 0.05$ compute the probability that at least one coin will have $v = 0$ for the case of $1$ coin, $1,000$ coins, $1,000,000$ coins. Repeat for μ = 0.8.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let $k_m$ be the number of heads for each coin. Since $\nu=0$ implies that $k=0$, we need to calculate&lt;/p&gt;

&lt;p&gt;$$ P\left[ k_1=0 \vee k_2=0 \vee &amp;hellip; k_m=0 \right] = P\left[ \bigvee\limits_{m} k_m = 0 \right]$$&lt;/p&gt;

&lt;p&gt;Here, we employ the common trick of computing the probability of the complement&lt;/p&gt;

&lt;p&gt;Note that the following step stems from the fact that $\mathbf{x}_{m,n}$ are independent. If we had used the same set of $N$ points for all $h_m$ (i.e. $\mathbf{x}_{m,n} \rightarrow \mathbf{x}_{n})$, the set of $k_m$ would not be independent, since looking at a specific $k_m$ would give you information regarding some other $k_{m^\prime}$.&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned}
  P\left[ \bigvee\limits_{m} k_m = 0 \right] &amp;amp;= 1 - P\left[ \bigwedge\limits_{m} k_m &amp;gt; 0 \right] \\&lt;br /&gt;
                                                   &amp;amp;= 1 - \prod\limits_{m}P\left[ k_m &amp;gt; 0 \right]
\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;Summing over the values of $k$ and using the fact that $\sum\limits_{k=0}^N P\left[k\right] = 1$ we can compute&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned}
  P\left[ k_m &amp;gt; 0 \right] &amp;amp;= \sum\limits_{i=1}^N P\left[k\right] \\&lt;br /&gt;
                             &amp;amp;= \sum\limits_{i=0}^N P\left[k\right] - P\left[0\right] \\&lt;br /&gt;
                             &amp;amp;= 1 - \left(1 - \mu\right)^N
\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;Thus, resulting in&lt;/p&gt;

&lt;p&gt;$$P\left[ \bigvee\limits_{m} k_m = 0 \right] = 1 - \left(  1 - \left(1 - \mu\right)^N \right)^M$$&lt;/p&gt;

&lt;p&gt;The result is intuitive. For a single coin, if $\left(1 - \mu\right)^N$ is the probability that &lt;strong&gt;all&lt;/strong&gt; $N$ flips result in tails, the complement $1 - \left(1 - \mu\right)^N$ is the probability that &lt;strong&gt;at least one&lt;/strong&gt; flip will result in heads. For this to happen to &lt;strong&gt;all&lt;/strong&gt; $M$ coins, we get $\left(  1 - \left(1 - \mu\right)^N \right)^M$. Similarly, the probability of the complement is $1 - \left(  1 - \left(1 - \mu\right)^N \right)^M$ and can be interpretated as the probability that &lt;strong&gt;at least one&lt;/strong&gt; coin out of $M$ will have &lt;strong&gt;all&lt;/strong&gt; flips out of $N$ resulting in tails.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at this in python.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import matplotlib.pyplot as plt
import pandas as pd

def prob_zero_error(μ: &#39;true probability of error&#39;,
                    M: &#39;number of hypotheses&#39;,
                    N: &#39;number of data points&#39;):
    return 1 - (1 - (1 - μ)**N)**M

d = [{&#39;μ&#39;: μ, 
      &#39;M&#39;: M, 
      &#39;p&#39;: prob_zero_error(μ, M, N=10)} 
     for μ in [0.05, 0.8] 
     for M in [1, 1_000, 1_000_000]]

pd.DataFrame(d).pivot(&#39;M&#39;, &#39;μ&#39;, &#39;p&#39;).to_html()
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;μ&lt;/th&gt;
      &lt;th&gt;0.05&lt;/th&gt;
      &lt;th&gt;0.5&lt;/th&gt;
      &lt;th&gt;0.8&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;M&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0.598737&lt;/td&gt;
      &lt;td&gt;0.000977&lt;/td&gt;
      &lt;td&gt;1.024000e-07&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1000&lt;/th&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.623576&lt;/td&gt;
      &lt;td&gt;1.023948e-04&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1000000&lt;/th&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;9.733159e-02&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We&amp;rsquo;ve included the results for $\mu = 0.5$, which represents a reasonable error rate for an untrained binary classification model. The middle cell tells us that a sample of size $NM = 10^4$ evaluated on $M=10^3$ hypotheses (with $10$ samples each) has a $62.36\%$ chance of at least one hypothesis having error zero.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at the asymptotic properties of $P(N,M) = 1 - \left(  1 - \left(1 - \mu\right)^N \right)^M$ for $\mu \in (0, 1)$.&lt;/p&gt;

&lt;p&gt;$$\lim\limits_{M \rightarrow \infty} P(N,M) = 1$$
$$\lim\limits_{N \rightarrow \infty} P(N,M) = 0$$&lt;/p&gt;

&lt;p&gt;Intuitvely, evaluating on more datapoints $N$ should make it harder for all points (coins) to have zero error (tails) for any number of hypotheses. Using a larger hypothesis set $\mid\mathcal{H}\mid = M$ is analogous to brute forcing the appearance of $k=0$ through repetitive attempts.&lt;/p&gt;

&lt;p&gt;If we want to bound this probability (for the sake of sanity) to some value $\lambda$, how should we chose $M$ and $N$? Solving independently for $N$ and $M$ in $P(N,M) \leq \lambda$&lt;/p&gt;

&lt;p&gt;$$M \leq \frac{log\left(1 - \lambda\right)}{log\left(1 - \left(1 - \mu\right)^N\right)}$$
$$N \geq \frac{log\left(1 - \sqrt[M]{1 - \lambda} \right)}{log\left(1 - \mu\right)}$$&lt;/p&gt;

&lt;p&gt;We can use these result to calculate how fast the number of hypotheses $M$ can grow with respect to the number of datapoints $N$ for a fixed probability of zero error $\lambda$, and vice-versa.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;(b) For the case $N = 6$ and $2$ coins with $\mu = 0.5$ for both coins, plot the probability $$P[ \max\limits_i \mid \nu_i - \mu_i \mid &amp;gt; \epsilon ]$$ for $\epsilon$ in the range $[0, 1]$ (the max is over coins). On the same plot show the bound that would be obtained using the Hoeffding Inequality. Remember that for a single coin, the Hoeffding bound is $$P[\mid \nu- \mu \mid &amp;gt; \epsilon ] \leq 2e^{-2N\epsilon^2}$$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import matplotlib.pyplot as plt
import numpy as np
plt.style.use(&#39;ggplot&#39;)

N = 6
M = 2
μ = 0.5

def hoeffding_bound(ε, N, M=1):
    return 2*M*np.exp(-2*N*ε**2)

def P(N, M, ε_space, μ):
    k = np.random.binomial(n=N,
                           p=μ,
                           size=(1_000, M))
    P = np.abs(k/N - μ).max(axis=1)
    return [(P &amp;gt; ε).mean() for ε in ε_space]

ε_space = np.linspace(0, 1, 100)
plt.figure(figsize=(12,5))
plt.plot(ε_space, hoeffding_bound(ε_space, N), &#39;--&#39;,
         ε_space, hoeffding_bound(ε_space, N, M=3), &#39;--&#39;, 
         ε_space, P(6, 2, ε_space, μ),
         ε_space, P(6, 10, ε_space, μ));
plt.title(&#39;Average over $1000$ iterations of\n&#39;
          &#39;$\max \{ \mid k_1/6 - 0.5 \mid,&#39;
          &#39;\mid k_2/6 - 0.5 \mid\} &amp;gt; \epsilon $\n&#39;,
          fontsize=20)
plt.legend([&#39;Hoeffding Bound &#39;
            &#39;($M=1 \\rightarrow 2e^{-12\epsilon^2}$)&#39;,
            &#39;Hoeffding Bound &#39;
            &#39;($M=3 \\rightarrow 6e^{-12\epsilon^2}$)&#39;,
            &#39;$M=2$&#39;,
            &#39;$M=3$&#39;], fontsize=18)
plt.yticks(fontsize=18)
plt.xticks(fontsize=18)
plt.ylim(0, 2)
plt.xlabel(&#39;$\epsilon$&#39;, fontsize=20);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;b.png&#34; alt=&#34;b.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice how the Hoeffding Bound is violated for $M=3$ if multiple hypotheses are not properly accounted for.&lt;/p&gt;

&lt;!---
&gt; [Hint: Use $P\[A\\space\\text{or}\\space B\] = P\[A\] + P\[B\] \\space \\space \\space \\space P\[A\\space\\text{and}\\space B\] = P\[A\] + P\[B\] - P\[A\] P\[B\]$, where the last equality follows by independence, to evaluate $P\[\\max \\dots \]]$.
--&gt;

&lt;hr /&gt;

&lt;p&gt;Questions, suggestions or corrections? Message me on &lt;a href=&#34;https://twitter.com/_dsevero&#34; target=&#34;_blank&#34;&gt;twitter&lt;/a&gt; or create a pull request at &lt;a href=&#34;https://github.com/dsevero/dsevero.com&#34; target=&#34;_blank&#34;&gt;dsevero/dsevero.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Consider leaving a &lt;span style=&#34;text-shadow: none;&#34;&gt;&lt;a class=&#34;github-button&#34; href=&#34;https://github.com/dsevero/dsevero.com&#34; data-icon=&#34;octicon-star&#34; data-size=&#34;small&#34; data-show-count=&#34;true&#34; aria-label=&#34;Star this on GitHub&#34;&gt;Star&lt;/a&gt;&lt;script async defer src=&#34;https://buttons.github.io/buttons.js&#34;&gt;&lt;/script&gt;&lt;/span&gt; if this helps you.&lt;/p&gt;

&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>Handling Time-series in Pandas and Numpy.</title>
      <link>/blog/pandas/</link>
      <pubDate>Fri, 25 Oct 2019 14:33:30 -0300</pubDate>
      <guid>/blog/pandas/</guid>
      <description>

&lt;p&gt;Here we will show you how to properly use the Python Data Analysis Library (pandas) and numpy. The agenda is:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;How to load data from csv files&lt;/li&gt;
&lt;li&gt;The basic pandas objects: DataFrames and Series&lt;/li&gt;
&lt;li&gt;Handling Time-Series data&lt;/li&gt;
&lt;li&gt;Resampling (optional)&lt;/li&gt;
&lt;li&gt;From pandas to numpy&lt;/li&gt;
&lt;li&gt;Simple Linear Regression&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Consider leaving a &lt;span style=&#34;text-shadow: none;&#34;&gt;&lt;a class=&#34;github-button&#34; href=&#34;https://github.com/dsevero/dsevero.com&#34; data-icon=&#34;octicon-star&#34; data-size=&#34;small&#34; data-show-count=&#34;true&#34; aria-label=&#34;Star this on GitHub&#34;&gt;Star&lt;/a&gt;&lt;script async defer src=&#34;https://buttons.github.io/buttons.js&#34;&gt;&lt;/script&gt;&lt;/span&gt; if this helps you.&lt;/p&gt;

&lt;p&gt;The following ipython magic (this is literally the name) will enable plots made by matplotlib to be rendered inside this notebook.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use(&#39;ggplot&#39;) # changes the plotting style
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;1-load-data&#34;&gt;1. Load data&lt;/h1&gt;

&lt;p&gt;The file &lt;code&gt;data/monthly-milk-production-pounds-p.csv&lt;/code&gt; contains the average monthly milk production, in pounds, of cows from Jan/1962 to Dec/1975. More information can be found here: &lt;a href=&#34;https://datamarket.com/data/set/22ox/monthly-milk-production-pounds-per-cow-jan-62-dec-75&#34; target=&#34;_blank&#34;&gt;https://datamarket.com/data/set/22ox/monthly-milk-production-pounds-per-cow-jan-62-dec-75&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;First, we must load this data with pandas for further analysis.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.read_csv(&#39;data/monthly-milk-production-pounds-p.csv&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Month&lt;/th&gt;
      &lt;th&gt;Monthly milk production: pounds per cow. Jan 62 ? Dec 75&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1962-01&lt;/td&gt;
      &lt;td&gt;589&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1962-02&lt;/td&gt;
      &lt;td&gt;561&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1962-03&lt;/td&gt;
      &lt;td&gt;640&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1962-04&lt;/td&gt;
      &lt;td&gt;656&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1962-05&lt;/td&gt;
      &lt;td&gt;727&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;type(df)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;pandas.core.frame.DataFrame
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Calling &lt;code&gt;.head()&lt;/code&gt; truncates the dataset to the first 5 lines (plus the header). Notice that the type of &lt;code&gt;df&lt;/code&gt; is a pandas DataFrame. This is similar to an Excel table, but much more powerful. Since pandas is a widely used library, Jupyter automatically shows the dataframe as a formatted HTML.&lt;/p&gt;

&lt;h1 id=&#34;2-the-basic-pandas-objects-dataframes-and-series&#34;&gt;2. The basic pandas objects: DataFrames and Series&lt;/h1&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at each column individually.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;Month&#39;].head()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    1962-01
1    1962-02
2    1962-03
3    1962-04
4    1962-05
Name: Month, dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;Monthly milk production: pounds per cow. Jan 62 ? Dec 75&#39;].head()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    589
1    561
2    640
3    656
4    727
Name: Monthly milk production: pounds per cow. Jan 62 ? Dec 75, dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;type(df[&#39;Month&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;pandas.core.series.Series
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A pandas Series is the second basic type. In a nutshell, Series are made up of values and an index. For both columns, the index can be seen printed on the far left and the elements are &lt;code&gt;0, 1, 2, 3,&lt;/code&gt; and &lt;code&gt;4&lt;/code&gt;. The values are the points of interest (e.g. dates for the &lt;code&gt;Month&lt;/code&gt; column and &lt;code&gt;589, 561, 640, 656&lt;/code&gt; and &lt;code&gt;727&lt;/code&gt; for the other).&lt;/p&gt;

&lt;p&gt;A pandas DataFrame is made up of multiple Series, each representing a column, and an index.&lt;/p&gt;

&lt;p&gt;The columns of a DataFrame can be accessed through slicing (as previously shown). Since the names are hard to write, we can change them like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.columns = [&#39;month&#39;, &#39;milk&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;3-handling-time-series-data&#34;&gt;3. Handling Time-Series data&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;month&lt;/th&gt;
      &lt;th&gt;milk&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1962-01&lt;/td&gt;
      &lt;td&gt;589&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1962-02&lt;/td&gt;
      &lt;td&gt;561&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1962-03&lt;/td&gt;
      &lt;td&gt;640&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1962-04&lt;/td&gt;
      &lt;td&gt;656&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1962-05&lt;/td&gt;
      &lt;td&gt;727&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.info()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
RangeIndex: 168 entries, 0 to 167
Data columns (total 2 columns):
month    168 non-null object
milk     168 non-null int64
dtypes: int64(1), object(1)
memory usage: 2.7+ KB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;.info()&lt;/code&gt; function gives us some insight on which data-types are being used to represent the values of each column. Notice how the &lt;code&gt;milk&lt;/code&gt; column is of type &lt;code&gt;int64&lt;/code&gt;. Hence, we can perform arithmetic and plotting operations like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;milk&#39;].plot();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./tutorial_21_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;milk&#39;].mean()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;754.7083333333334
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;milk&#39;].var()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;10445.764720558882
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;month&lt;/code&gt; column is of type &lt;code&gt;object&lt;/code&gt;. This is python&amp;rsquo;s way of telling you that this column is of mixed type. Hence, it is a little bit trickier to manipulate. Due to the internals of pandas, a Series that has all values of type &lt;code&gt;str&lt;/code&gt; will still be refered to as of type &lt;code&gt;object&lt;/code&gt;. This is the case of the &lt;code&gt;month&lt;/code&gt; column.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;month&#39;].apply(type).unique()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([&amp;lt;class &#39;str&#39;&amp;gt;], dtype=object)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;.apply&lt;/code&gt; function will apply the argument function (in this case &lt;code&gt;type&lt;/code&gt;) to every single element of the series. &lt;code&gt;unique&lt;/code&gt; will return to us the unique values of the series (i.e. it will drop all duplicates). Calling both together let&amp;rsquo;s us see what data-types are present in the Series. As can be seen, all are of type &lt;code&gt;str&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;pandas has a built-in timestamp data-type. It works like so.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.Timestamp(&#39;now&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Timestamp(&#39;2019-10-25 14:42:25.259875&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.Timestamp(&#39;1992-03-23&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Timestamp(&#39;1992-03-23 00:00:00&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.Timestamp(&#39;1992-03-23 04&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Timestamp(&#39;1992-03-23 04:00:00&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Internally, pandas stores a date as the amount of time that has passed since &lt;code&gt;1970-01-01 00:00:00&lt;/code&gt;. This date is represented as &lt;code&gt;pd.Timestamp(0)&lt;/code&gt;. This is useful for linear regression, since it allows us to convert timestamp data to integers without loss of reference.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.Timestamp(0)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Timestamp(&#39;1970-01-01 00:00:00&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.Timestamp(&#39;now&#39;) &amp;gt; pd.Timestamp(&#39;1992-03-23 04&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can transform the &lt;code&gt;month&lt;/code&gt; column into &lt;code&gt;pd.Timestamp&lt;/code&gt; values with &lt;code&gt;pd.to_datetime&lt;/code&gt; and set it as the index of a new time-series.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;month&#39;] = pd.to_datetime(df[&#39;month&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s = df.set_index(&#39;month&#39;)[&#39;milk&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;month
1962-01-01    589
1962-02-01    561
1962-03-01    640
1962-04-01    656
1962-05-01    727
Name: milk, dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.index[0]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Timestamp(&#39;1962-01-01 00:00:00&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.values[0]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;589
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.plot();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./tutorial_40_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice how the x-axis of the above plot differs from the first one of this same section, since the index of &lt;code&gt;s&lt;/code&gt; is a timestamp-like-type. The timestamp index of &lt;code&gt;s&lt;/code&gt; is also manipulatable. Time-aware slices are also now available.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.index.min()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Timestamp(&#39;1962-01-01 00:00:00&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.index.max()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Timestamp(&#39;1975-12-01 00:00:00&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s[&#39;1970&#39;].plot();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./tutorial_44_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s[&#39;1970&#39;:&#39;1972&#39;].plot(style=&#39;o--&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./tutorial_45_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;4-resampling-optional&#34;&gt;4. Resampling (optional)&lt;/h1&gt;

&lt;p&gt;Looking at the plots it is pretty clear that the data trend is rising, but it fluctuates yearly reaching a local peak around June. How can we calculate the yearly mean as an attempt to smooth out the data? Luckily, &lt;code&gt;s&lt;/code&gt; is a time-series (i.e. has a time index and numeric values), we can use the &lt;code&gt;.resample&lt;/code&gt; function. This will allow us to group the data chronologically, given that we supply an aggregating function (i.e. &lt;code&gt;mean&lt;/code&gt;, &lt;code&gt;std&lt;/code&gt;, &lt;code&gt;var&lt;/code&gt;, &lt;code&gt;median&lt;/code&gt;, etc).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.resample(&#39;12M&#39;).mean().plot(style=&#39;o--&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./tutorial_48_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.resample(&#39;6M&#39;).mean().plot(style=&#39;o--&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./tutorial_49_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;5-from-pandas-to-numpy&#34;&gt;5. From pandas to numpy&lt;/h1&gt;

&lt;p&gt;Numpy provides vector data-types and operations making it easy to work with linear algebra. In fact, this works so well, that pandas is actually built on top of numpy. The values of a pandas Series, and the values of the index are numpy ndarrays.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;type(s.values)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;numpy.ndarray
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;type(s.index.values)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;numpy.ndarray
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.head().values
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([589, 561, 640, 656, 727])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.head().index.values
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([&#39;1962-01-01T00:00:00.000000000&#39;, &#39;1962-02-01T00:00:00.000000000&#39;,
       &#39;1962-03-01T00:00:00.000000000&#39;, &#39;1962-04-01T00:00:00.000000000&#39;,
       &#39;1962-05-01T00:00:00.000000000&#39;], dtype=&#39;datetime64[ns]&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.values.dot(s.values) # dot product
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;97434667
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.values + s.values
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([1178, 1122, 1280, 1312, 1454, 1394, 1280, 1198, 1136, 1154, 1106,
       1164, 1200, 1132, 1306, 1346, 1484, 1432, 1320, 1234, 1166, 1174,
       1130, 1196, 1256, 1236, 1376, 1410, 1540, 1472, 1356, 1278, 1208,
       1222, 1188, 1268, 1316, 1244, 1418, 1444, 1564, 1512, 1404, 1306,
       1230, 1242, 1204, 1270, 1354, 1270, 1472, 1510, 1622, 1596, 1470,
       1394, 1322, 1334, 1290, 1376, 1426, 1334, 1524, 1568, 1674, 1634,
       1534, 1444, 1362, 1374, 1320, 1396, 1434, 1392, 1550, 1592, 1716,
       1652, 1566, 1480, 1402, 1412, 1354, 1422, 1468, 1380, 1570, 1610,
       1742, 1690, 1602, 1528, 1450, 1446, 1380, 1468, 1500, 1414, 1614,
       1648, 1772, 1718, 1638, 1566, 1480, 1494, 1422, 1502, 1608, 1512,
       1720, 1756, 1884, 1826, 1738, 1668, 1580, 1600, 1526, 1600, 1652,
       1598, 1780, 1800, 1922, 1870, 1788, 1710, 1618, 1620, 1532, 1610,
       1642, 1546, 1766, 1796, 1914, 1848, 1762, 1674, 1568, 1582, 1520,
       1604, 1656, 1556, 1778, 1804, 1938, 1894, 1816, 1734, 1630, 1624,
       1546, 1626, 1668, 1564, 1784, 1806, 1932, 1874, 1792, 1716, 1634,
       1654, 1594, 1686])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.values * s.values
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([346921, 314721, 409600, 430336, 528529, 485809, 409600, 358801,
       322624, 332929, 305809, 338724, 360000, 320356, 426409, 452929,
       550564, 512656, 435600, 380689, 339889, 344569, 319225, 357604,
       394384, 381924, 473344, 497025, 592900, 541696, 459684, 408321,
       364816, 373321, 352836, 401956, 432964, 386884, 502681, 521284,
       611524, 571536, 492804, 426409, 378225, 385641, 362404, 403225,
       458329, 403225, 541696, 570025, 657721, 636804, 540225, 485809,
       436921, 444889, 416025, 473344, 508369, 444889, 580644, 614656,
       700569, 667489, 588289, 521284, 463761, 471969, 435600, 487204,
       514089, 484416, 600625, 633616, 736164, 682276, 613089, 547600,
       491401, 498436, 458329, 505521, 538756, 476100, 616225, 648025,
       758641, 714025, 641601, 583696, 525625, 522729, 476100, 538756,
       562500, 499849, 651249, 678976, 784996, 737881, 670761, 613089,
       547600, 558009, 505521, 564001, 646416, 571536, 739600, 770884,
       887364, 833569, 755161, 695556, 624100, 640000, 582169, 640000,
       682276, 638401, 792100, 810000, 923521, 874225, 799236, 731025,
       654481, 656100, 586756, 648025, 674041, 597529, 779689, 806404,
       915849, 853776, 776161, 700569, 614656, 625681, 577600, 643204,
       685584, 605284, 790321, 813604, 938961, 896809, 824464, 751689,
       664225, 659344, 597529, 660969, 695556, 611524, 795664, 815409,
       933156, 877969, 802816, 736164, 667489, 683929, 635209, 710649])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above examples are just for show. You can do the same thing directly with pandas Series objects and it will use numpy behind the scenes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s.dot(s) == s.values.dot(s.values)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;6-simple-linear-regression&#34;&gt;6. Simple Linear Regression.&lt;/h1&gt;

&lt;p&gt;Side note: python accepts non-ascii type characters. So it is possible to use greek letters as variables. Try this: type in &lt;code&gt;\alpha&lt;/code&gt; and press the TAB key in any cell.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;α = 1
β = 2
α + β
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we will implement a simple linear regression to illustrate the full usage of pandas with numpy. For a single variable with intercept: $y = \alpha + \beta x$, the closed form solution is:&lt;/p&gt;

&lt;p&gt;$$\beta = \frac{cov(x,y)}{var(x)}$$
$$\alpha = \bar{y} - \beta \bar{x}$$&lt;/p&gt;

&lt;p&gt;where $\bar{y}$ and $\bar{x}$ are the average values of the vectors $y$ and $x$, respectively.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;y = s
x = (s.index - pd.Timestamp(0)).days.values
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;β = np.cov([x,y])[0][1]/x.var()
α = y.mean() - β*x.mean()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;α
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;776.0355721497116
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;β
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.05592981987998409
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(
    s
    .to_frame() # transforms s back into a DataFrame
    .assign(regression = α + β*x) # creates a new column called regression with values α + β*x
    .plot() # plots all columns
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./tutorial_69_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The above programming style is called method chaining, and is highly recommended for clarity.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Report on the Ziggurat Method</title>
      <link>/blog/ziggurat/</link>
      <pubDate>Mon, 23 Sep 2019 01:50:44 -0300</pubDate>
      <guid>/blog/ziggurat/</guid>
      <description>&lt;p&gt;&lt;meta http-equiv=&#34;refresh&#34; content=&#34;0; url=http://example.com/&#34;/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ad hoc Big Data Analysis with Dask</title>
      <link>/blog/dask/</link>
      <pubDate>Mon, 19 Mar 2018 00:00:00 +0000</pubDate>
      <guid>/blog/dask/</guid>
      <description>

&lt;p&gt;Creating custom reports and machine learning models with pandas can be cumbersome with limited hardware resources (memory and CPU). Financial constraints can make spawning cloud instances to side-step this issue a problem, while adding the complexity of libraries such as Apache Spark isn&amp;rsquo;t worth the trouble and staggers data exploration. &lt;strong&gt;How can we keep the simplicity and power of pandas, while extending it to be out-of-core and parallel?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Enter &lt;a href=&#34;https://dask.pydata.org/en/latest/&#34; target=&#34;_blank&#34;&gt;Dask&lt;/a&gt;: a flexible parallel computing library for analytic computing. With it we will create a linear regression model to predict &lt;a href=&#34;https://help.medium.com/hc/en-us/articles/214991667-Read-time&#34; target=&#34;_blank&#34;&gt;read time in Medium posts&lt;/a&gt; using a Kaggle dataset, while comparing the equivalent implementation with pandas.&lt;/p&gt;

&lt;p&gt;Consider leaving a &lt;span style=&#34;text-shadow: none;&#34;&gt;&lt;a class=&#34;github-button&#34; href=&#34;https://github.com/dsevero/dsevero.com&#34; data-icon=&#34;octicon-star&#34; data-size=&#34;small&#34; data-show-count=&#34;true&#34; aria-label=&#34;Star this on GitHub&#34;&gt;Star&lt;/a&gt;&lt;script async defer src=&#34;https://buttons.github.io/buttons.js&#34;&gt;&lt;/script&gt;&lt;/span&gt; if this helps you.&lt;/p&gt;

&lt;h3 id=&#34;1-kaggle-data&#34;&gt;1. Kaggle data&lt;/h3&gt;

&lt;p&gt;We will be using the official kaggle api to automate our data fetching process.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Log on to kaggle and enter the &lt;a href=&#34;https://www.kaggle.com/c/how-good-is-your-medium-article&#34; target=&#34;_blank&#34;&gt;How good is your Medium article?&lt;/a&gt; competition.&lt;/li&gt;
&lt;li&gt;Configure the official kaggle api &lt;a href=&#34;https://github.com/Kaggle/kaggle-api&#34; target=&#34;_blank&#34;&gt;following these steps&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For this tutorial we will need only 1 file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kaggle competitions download -c how-good-is-your-medium-article -f train.json.gz

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The reason for decompressing will become clear later.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gunzip -k ~/.kaggle/competitions/how-good-is-your-medium-article/train.json.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This sample file will help us speed up the analysis.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;head -n5 ~/.kaggle/competitions/how-good-is-your-medium-article/train.json &amp;gt; \
         ~/.kaggle/competitions/how-good-is-your-medium-article/train-sample.json
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-exploration&#34;&gt;2. Exploration.&lt;/h3&gt;

&lt;p&gt;Despite the extension being json our data is stored as &lt;a href=&#34;http://jsonlines.org/&#34; target=&#34;_blank&#34;&gt;jsonl&lt;/a&gt;. This means that each line of &lt;code&gt;train.json&lt;/code&gt; is a valid json file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;head -n1 ~/.kaggle/competitions/how-good-is-your-medium-article/train.json | jq &#39;del(.content)&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;_id&amp;quot;: &amp;quot;https://medium.com/policy/medium-terms-of-service-9db0094a1e0f&amp;quot;,
  &amp;quot;_timestamp&amp;quot;: 1520035195.282891,
  &amp;quot;_spider&amp;quot;: &amp;quot;medium&amp;quot;,
  &amp;quot;url&amp;quot;: &amp;quot;https://medium.com/policy/medium-terms-of-service-9db0094a1e0f&amp;quot;,
  &amp;quot;domain&amp;quot;: &amp;quot;medium.com&amp;quot;,
  &amp;quot;published&amp;quot;: {
    &amp;quot;$date&amp;quot;: &amp;quot;2012-08-13T22:54:53.510Z&amp;quot;
  },
  &amp;quot;title&amp;quot;: &amp;quot;Medium Terms of Service – Medium Policy – Medium&amp;quot;,
  &amp;quot;author&amp;quot;: {
    &amp;quot;name&amp;quot;: null,
    &amp;quot;url&amp;quot;: &amp;quot;https://medium.com/@Medium&amp;quot;,
    &amp;quot;twitter&amp;quot;: &amp;quot;@Medium&amp;quot;
  },
  &amp;quot;image_url&amp;quot;: null,
  &amp;quot;tags&amp;quot;: [],
  &amp;quot;link_tags&amp;quot;: {
    &amp;quot;canonical&amp;quot;: &amp;quot;https://medium.com/policy/medium-terms-of-service-9db0094a1e0f&amp;quot;,
    &amp;quot;publisher&amp;quot;: &amp;quot;https://plus.google.com/103654360130207659246&amp;quot;,
    &amp;quot;author&amp;quot;: &amp;quot;https://medium.com/@Medium&amp;quot;,
    &amp;quot;search&amp;quot;: &amp;quot;/osd.xml&amp;quot;,
    &amp;quot;alternate&amp;quot;: &amp;quot;android-app://com.medium.reader/https/medium.com/p/9db0094a1e0f&amp;quot;,
    &amp;quot;stylesheet&amp;quot;: &amp;quot;https://cdn-static-1.medium.com/_/fp/css/main-branding-base.Ch8g7KPCoGXbtKfJaVXo_w.css&amp;quot;,
    &amp;quot;icon&amp;quot;: &amp;quot;https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico&amp;quot;,
    &amp;quot;apple-touch-icon&amp;quot;: &amp;quot;https://cdn-images-1.medium.com/fit/c/120/120/1*6_fgYnisCa9V21mymySIvA.png&amp;quot;,
    &amp;quot;mask-icon&amp;quot;: &amp;quot;https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg&amp;quot;
  },
  &amp;quot;meta_tags&amp;quot;: {
    &amp;quot;viewport&amp;quot;: &amp;quot;width=device-width, initial-scale=1&amp;quot;,
    &amp;quot;title&amp;quot;: &amp;quot;Medium Terms of Service – Medium Policy – Medium&amp;quot;,
    &amp;quot;referrer&amp;quot;: &amp;quot;unsafe-url&amp;quot;,
    &amp;quot;description&amp;quot;: &amp;quot;These Terms of Service (“Terms”) are a contract between you and A Medium Corporation. They govern your use of Medium’s sites, services, mobile apps, products, and content (“Services”). By using…&amp;quot;,
    &amp;quot;theme-color&amp;quot;: &amp;quot;#000000&amp;quot;,
    &amp;quot;og:title&amp;quot;: &amp;quot;Medium Terms of Service – Medium Policy – Medium&amp;quot;,
    &amp;quot;og:url&amp;quot;: &amp;quot;https://medium.com/policy/medium-terms-of-service-9db0094a1e0f&amp;quot;,
    &amp;quot;fb:app_id&amp;quot;: &amp;quot;542599432471018&amp;quot;,
    &amp;quot;og:description&amp;quot;: &amp;quot;These Terms of Service (“Terms”) are a contract between you and A Medium Corporation. They govern your use of Medium’s sites, services, mobile apps, products, and content (“Services”). By using…&amp;quot;,
    &amp;quot;twitter:description&amp;quot;: &amp;quot;These Terms of Service (“Terms”) are a contract between you and A Medium Corporation. They govern your use of Medium’s sites, services, mobile apps, products, and content (“Services”). By using…&amp;quot;,
    &amp;quot;author&amp;quot;: &amp;quot;Medium&amp;quot;,
    &amp;quot;og:type&amp;quot;: &amp;quot;article&amp;quot;,
    &amp;quot;twitter:card&amp;quot;: &amp;quot;summary&amp;quot;,
    &amp;quot;article:publisher&amp;quot;: &amp;quot;https://www.facebook.com/medium&amp;quot;,
    &amp;quot;article:author&amp;quot;: &amp;quot;https://medium.com/@Medium&amp;quot;,
    &amp;quot;robots&amp;quot;: &amp;quot;index, follow&amp;quot;,
    &amp;quot;article:published_time&amp;quot;: &amp;quot;2012-08-13T22:54:53.510Z&amp;quot;,
    &amp;quot;twitter:creator&amp;quot;: &amp;quot;@Medium&amp;quot;,
    &amp;quot;twitter:site&amp;quot;: &amp;quot;@Medium&amp;quot;,
    &amp;quot;og:site_name&amp;quot;: &amp;quot;Medium&amp;quot;,
    &amp;quot;twitter:label1&amp;quot;: &amp;quot;Reading time&amp;quot;,
    &amp;quot;twitter:data1&amp;quot;: &amp;quot;5 min read&amp;quot;,
    &amp;quot;twitter:app:name:iphone&amp;quot;: &amp;quot;Medium&amp;quot;,
    &amp;quot;twitter:app:id:iphone&amp;quot;: &amp;quot;828256236&amp;quot;,
    &amp;quot;twitter:app:url:iphone&amp;quot;: &amp;quot;medium://p/9db0094a1e0f&amp;quot;,
    &amp;quot;al:ios:app_name&amp;quot;: &amp;quot;Medium&amp;quot;,
    &amp;quot;al:ios:app_store_id&amp;quot;: &amp;quot;828256236&amp;quot;,
    &amp;quot;al:android:package&amp;quot;: &amp;quot;com.medium.reader&amp;quot;,
    &amp;quot;al:android:app_name&amp;quot;: &amp;quot;Medium&amp;quot;,
    &amp;quot;al:ios:url&amp;quot;: &amp;quot;medium://p/9db0094a1e0f&amp;quot;,
    &amp;quot;al:android:url&amp;quot;: &amp;quot;medium://p/9db0094a1e0f&amp;quot;,
    &amp;quot;al:web:url&amp;quot;: &amp;quot;https://medium.com/policy/medium-terms-of-service-9db0094a1e0f&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;ve ommited the &lt;code&gt;content&lt;/code&gt; field due to it&amp;rsquo;s huge verbosity. Our problem requires that we use the fields &lt;code&gt;published.$date&lt;/code&gt; and &lt;code&gt;meta_tags.twitter:data&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;head -n10 train.json | jq &#39;[.published[&amp;quot;$date&amp;quot;], .meta_tags[&amp;quot;twitter:data1&amp;quot;]] | @csv&#39; -r
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;2012-08-13T22:54:53.510Z&amp;quot;,&amp;quot;5 min read&amp;quot;
&amp;quot;2015-08-03T07:44:50.331Z&amp;quot;,&amp;quot;7 min read&amp;quot;
&amp;quot;2017-02-05T13:08:17.410Z&amp;quot;,&amp;quot;2 min read&amp;quot;
&amp;quot;2017-05-06T08:16:30.776Z&amp;quot;,&amp;quot;3 min read&amp;quot;
&amp;quot;2017-06-04T14:46:25.772Z&amp;quot;,&amp;quot;4 min read&amp;quot;
&amp;quot;2017-04-02T16:21:15.171Z&amp;quot;,&amp;quot;7 min read&amp;quot;
&amp;quot;2016-08-15T04:16:02.103Z&amp;quot;,&amp;quot;12 min read&amp;quot;
&amp;quot;2015-01-14T21:31:07.568Z&amp;quot;,&amp;quot;5 min read&amp;quot;
&amp;quot;2014-02-11T04:11:54.771Z&amp;quot;,&amp;quot;4 min read&amp;quot;
&amp;quot;2015-10-25T02:58:05.551Z&amp;quot;,&amp;quot;8 min read&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-building-the-time-series-the-good-the-bad-and-the-ugly&#34;&gt;3. Building the time-series: The good, the bad and the ugly.&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import json
import pandas as pd
import numpy as np
import os
import dask.bag as db

from toolz.curried import get
from typing import Dict

HOME = os.environ[&#39;HOME&#39;]
KAGGLE_DATASET_HOME = &#39;.kaggle/competitions/how-good-is-your-medium-article/&#39;
train_file = f&#39;{HOME}/{KAGGLE_DATASET_HOME}/train.json&#39;
train_sample_file = f&#39;{HOME}/{KAGGLE_DATASET_HOME}/train-sample.json&#39;
MEGABYTES = 1024**2
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;the-ugly&#34;&gt;The Ugly&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;read_json&lt;/code&gt; loads each json as a record, parsing each object beforehand.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(
    pd
    .read_json(train_sample_file, lines=True)
    [[&#39;published&#39;, &#39;meta_tags&#39;]]
)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;published&lt;/th&gt;
      &lt;th&gt;meta_tags&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;{&#39;$date&#39;: &#39;2012-08-13T22:54:53.510Z&#39;}&lt;/td&gt;
      &lt;td&gt;{&#39;viewport&#39;: &#39;width=device-width, initial-scal...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;{&#39;$date&#39;: &#39;2015-08-03T07:44:50.331Z&#39;}&lt;/td&gt;
      &lt;td&gt;{&#39;viewport&#39;: &#39;width=device-width, initial-scal...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;{&#39;$date&#39;: &#39;2017-02-05T13:08:17.410Z&#39;}&lt;/td&gt;
      &lt;td&gt;{&#39;viewport&#39;: &#39;width=device-width, initial-scal...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;{&#39;$date&#39;: &#39;2017-05-06T08:16:30.776Z&#39;}&lt;/td&gt;
      &lt;td&gt;{&#39;viewport&#39;: &#39;width=device-width, initial-scal...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;{&#39;$date&#39;: &#39;2017-06-04T14:46:25.772Z&#39;}&lt;/td&gt;
      &lt;td&gt;{&#39;viewport&#39;: &#39;width=device-width, initial-scal...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Both columns have object values. Our fields of interest can be extracted and assigned to a new column using the &lt;code&gt;assign&lt;/code&gt; function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(
    _
    .assign(
        published_timestamp = lambda df: df[&#39;published&#39;].apply(dict.get, args=(&#39;$date&#39;,)),
        read_time = lambda df: df[&#39;meta_tags&#39;].apply(dict.get, args=(&#39;twitter:data1&#39;,)),
    )
)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;published&lt;/th&gt;
      &lt;th&gt;meta_tags&lt;/th&gt;
      &lt;th&gt;published_timestamp&lt;/th&gt;
      &lt;th&gt;read_time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;{&#39;$date&#39;: &#39;2012-08-13T22:54:53.510Z&#39;}&lt;/td&gt;
      &lt;td&gt;{&#39;viewport&#39;: &#39;width=device-width, initial-scal...&lt;/td&gt;
      &lt;td&gt;2012-08-13T22:54:53.510Z&lt;/td&gt;
      &lt;td&gt;5 min read&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;{&#39;$date&#39;: &#39;2015-08-03T07:44:50.331Z&#39;}&lt;/td&gt;
      &lt;td&gt;{&#39;viewport&#39;: &#39;width=device-width, initial-scal...&lt;/td&gt;
      &lt;td&gt;2015-08-03T07:44:50.331Z&lt;/td&gt;
      &lt;td&gt;7 min read&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;{&#39;$date&#39;: &#39;2017-02-05T13:08:17.410Z&#39;}&lt;/td&gt;
      &lt;td&gt;{&#39;viewport&#39;: &#39;width=device-width, initial-scal...&lt;/td&gt;
      &lt;td&gt;2017-02-05T13:08:17.410Z&lt;/td&gt;
      &lt;td&gt;2 min read&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;{&#39;$date&#39;: &#39;2017-05-06T08:16:30.776Z&#39;}&lt;/td&gt;
      &lt;td&gt;{&#39;viewport&#39;: &#39;width=device-width, initial-scal...&lt;/td&gt;
      &lt;td&gt;2017-05-06T08:16:30.776Z&lt;/td&gt;
      &lt;td&gt;3 min read&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;{&#39;$date&#39;: &#39;2017-06-04T14:46:25.772Z&#39;}&lt;/td&gt;
      &lt;td&gt;{&#39;viewport&#39;: &#39;width=device-width, initial-scal...&lt;/td&gt;
      &lt;td&gt;2017-06-04T14:46:25.772Z&lt;/td&gt;
      &lt;td&gt;4 min read&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Extracting the time value in &lt;code&gt;read_time&lt;/code&gt; can be done with &lt;code&gt;pd.Series.str&lt;/code&gt; processing methods. When called, the equivalent function is applied to each value, hence &lt;code&gt;.str.split(&#39; &#39;).str[0]&lt;/code&gt; is equivalent to &lt;code&gt;&#39;5 min read&#39;.split(&#39; &#39;)[0]&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;astype&lt;/code&gt; casts our columns to the necessary dtypes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(
    _
    .assign(read_time = lambda df: df[&#39;read_time&#39;].str.split(&#39; &#39;).str[0])
    .astype({
        &#39;read_time&#39;: int,
        &#39;published_timestamp&#39;: &#39;datetime64[ns]&#39;
    })
    .set_index(&#39;published_timestamp&#39;)
    [&#39;read_time&#39;]
    .to_frame()
)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;read_time&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;published_timestamp&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-08-13 22:54:53.510&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-08-03 07:44:50.331&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2017-02-05 13:08:17.410&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2017-05-06 08:16:30.776&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2017-06-04 14:46:25.772&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h4 id=&#34;the-bad&#34;&gt;The Bad&lt;/h4&gt;

&lt;p&gt;The issue with The Ugly solution is that &lt;code&gt;read_json&lt;/code&gt; loads the entire dataset into memory before slicing the necessary columns (&lt;code&gt;published&lt;/code&gt; and &lt;code&gt;meta_tags&lt;/code&gt;). Pre-processing our data with pure python consumes less RAM.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_datum(x):
    return {
        &#39;published_timestamp&#39;: x[&#39;published&#39;][&#39;$date&#39;],
        &#39;read_time&#39;: x[&#39;meta_tags&#39;][&#39;twitter:data1&#39;]
    }

with open(train_sample_file, &#39;r&#39;) as f:    
    bad_df = pd.DataFrame([make_datum(json.loads(x)) for x in f])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;bad_df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;published_timestamp&lt;/th&gt;
      &lt;th&gt;read_time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2012-08-13T22:54:53.510Z&lt;/td&gt;
      &lt;td&gt;5 min read&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2015-08-03T07:44:50.331Z&lt;/td&gt;
      &lt;td&gt;7 min read&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2017-02-05T13:08:17.410Z&lt;/td&gt;
      &lt;td&gt;2 min read&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;2017-05-06T08:16:30.776Z&lt;/td&gt;
      &lt;td&gt;3 min read&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;2017-06-04T14:46:25.772Z&lt;/td&gt;
      &lt;td&gt;4 min read&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(
    _
    .assign(read_time = lambda x: x[&#39;read_time&#39;].str.split(&#39; &#39;).str[0])
    .astype({
        &#39;published_timestamp&#39;: &#39;datetime64[ns]&#39;,
        &#39;read_time&#39;: int
    })
    .set_index(&#39;published_timestamp&#39;)
    [&#39;read_time&#39;]
    .to_frame()
)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;read_time&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;published_timestamp&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-08-13 22:54:53.510&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-08-03 07:44:50.331&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2017-02-05 13:08:17.410&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2017-05-06 08:16:30.776&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2017-06-04 14:46:25.772&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h4 id=&#34;the-good&#34;&gt;The Good&lt;/h4&gt;

&lt;p&gt;Dask allows us to build lazy computational graphs. For example, &lt;code&gt;db.read_text&lt;/code&gt; will return a reference to each line of our jsonl file. After, &lt;code&gt;.map&lt;/code&gt; applies &lt;code&gt;json.loads&lt;/code&gt; to each line and &lt;code&gt;.to_dataframe&lt;/code&gt; casts the data to a dask DataFrame preserving &lt;strong&gt;only&lt;/strong&gt; the columns we explicitly tell it (in this case &lt;code&gt;published&lt;/code&gt; and &lt;code&gt;meta_tags&lt;/code&gt;). The rest of the code proceeds analogously with the previous implementations. The only difference is that &lt;strong&gt;dask won&amp;rsquo;t actually process anything until we call the &lt;code&gt;.compute&lt;/code&gt; method&lt;/strong&gt;, returning a pandas DataFrame. In other words, a dask DataFrame is a lazy version of a pandas DataFrame. The same is true for series.&lt;/p&gt;

&lt;p&gt;Notice how we pass the &lt;code&gt;blocksize&lt;/code&gt; parameter as 100 MB. Since our file has 2 GB, dask creates 20 independent partitions. Most methods that are called (like &lt;code&gt;.map&lt;/code&gt; and &lt;code&gt;.assign&lt;/code&gt;) run in parallel, potentially speeding up computation significantly. Memory is also spared, since we only load the fields we need.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dag = (
    db
    .read_text(train_file, blocksize=100*MEGABYTES)
    .map(json.loads)
    .to_dataframe({
        &#39;published&#39;: object,
        &#39;meta_tags&#39;: object
    })
    .assign(
        published_timestamp=lambda df: df[&#39;published&#39;].apply(get(&#39;$date&#39;)),
        read_time=lambda df: df[&#39;meta_tags&#39;].apply(get(&#39;twitter:data1&#39;)).str.split(&#39; &#39;).str[0],
    )
    .astype({
        &#39;published_timestamp&#39;: &#39;datetime64[ns]&#39;,
        &#39;read_time&#39;: int
    })
    [[&#39;published_timestamp&#39;, &#39;read_time&#39;]]
)

dag
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;&lt;strong&gt;Dask DataFrame Structure:&lt;/strong&gt;&lt;/div&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;published_timestamp&lt;/th&gt;
      &lt;th&gt;read_time&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;npartitions=20&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;td&gt;datetime64[ns]&lt;/td&gt;
      &lt;td&gt;int64&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div&gt;Dask Name: getitem, 120 tasks&lt;/div&gt;

&lt;p&gt;Other methods like &lt;code&gt;.head(N)&lt;/code&gt; also force the dataframe to be computed. Since this call needs only the first &lt;code&gt;N&lt;/code&gt; rows, dask will partially solve the graph such that only those are processed.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(
    _
    .head()
    .set_index(&#39;published_timestamp&#39;)
)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;read_time&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;published_timestamp&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-08-13 22:54:53.510&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-08-03 07:44:50.331&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2017-02-05 13:08:17.410&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2017-05-06 08:16:30.776&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2017-06-04 14:46:25.772&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h1 id=&#34;4-prediction&#34;&gt;4. Prediction&lt;/h1&gt;

&lt;p&gt;Here we will implement simple linear regression for a single variable with intercept: $y = \alpha + \beta x$, the closed form solution is:&lt;/p&gt;

&lt;p&gt;$$\beta = \frac{cov(x,y)}{var(x)}$$
$$\alpha = \bar{y} - \beta \bar{x}$$&lt;/p&gt;

&lt;p&gt;where $\bar{y}$ and $\bar{x}$ are the average values of the vectors $y$ and $x$, respectively.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def linear_regression(y: np.array, x: np.array, prefix=&#39;&#39;) -&amp;gt; Dict[str, float]:
    M = np.cov(x, y)
    beta = M[0,1]/M[0,0]
    alpha = y.mean() - beta*x.mean()
    return {
        prefix + &#39;alpha&#39;: alpha, 
        prefix + &#39;beta&#39;: beta
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = (
    dag
    .compute()
    .set_index(&#39;published_timestamp&#39;)
    [&#39;2015&#39;:]
    [&#39;read_time&#39;]
    .groupby(lambda i: pd.to_datetime(i.strftime(&#39;%Y/%m&#39;)))
    .agg([&#39;mean&#39;, &#39;sum&#39;])
)

df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;th&gt;sum&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-01-01&lt;/th&gt;
      &lt;td&gt;8.380952&lt;/td&gt;
      &lt;td&gt;4928&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-02-01&lt;/th&gt;
      &lt;td&gt;7.887564&lt;/td&gt;
      &lt;td&gt;4630&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-03-01&lt;/th&gt;
      &lt;td&gt;7.907840&lt;/td&gt;
      &lt;td&gt;5749&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-04-01&lt;/th&gt;
      &lt;td&gt;7.667149&lt;/td&gt;
      &lt;td&gt;5298&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-05-01&lt;/th&gt;
      &lt;td&gt;8.307506&lt;/td&gt;
      &lt;td&gt;6862&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.plot(
    style=[&#39;o--&#39;, &#39;og--&#39;], figsize=(12,6),
    subplots=True, title=&#39;Medium read time&#39;, fontsize=12
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./2018-03-19%20Ad%20hoc%20Big%20Data%20Analysis%20with%20Dask_32_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df_pred = (
    df
    .assign(**linear_regression(df[&#39;mean&#39;], df.index.asi8, prefix=&#39;mean_&#39;))
    .assign(**linear_regression(df[&#39;sum&#39;], df.index.asi8, prefix=&#39;sum_&#39;))
    .assign(mean_pred = lambda z: z[&#39;mean_alpha&#39;] + z[&#39;mean_beta&#39;]*z.index.asi8)
    .assign(sum_pred = lambda z: z[&#39;sum_alpha&#39;] + z[&#39;sum_beta&#39;]*z.index.asi8)
)

df_pred[[&#39;mean_alpha&#39;, &#39;mean_beta&#39;, &#39;sum_alpha&#39;, &#39;sum_beta&#39;, &#39;mean_pred&#39;, &#39;sum_pred&#39;]].head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;mean_alpha&lt;/th&gt;
      &lt;th&gt;mean_beta&lt;/th&gt;
      &lt;th&gt;sum_alpha&lt;/th&gt;
      &lt;th&gt;sum_beta&lt;/th&gt;
      &lt;th&gt;mean_pred&lt;/th&gt;
      &lt;th&gt;sum_pred&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-01-01&lt;/th&gt;
      &lt;td&gt;27.130799&lt;/td&gt;
      &lt;td&gt;-1.351069e-17&lt;/td&gt;
      &lt;td&gt;-407905.660648&lt;/td&gt;
      &lt;td&gt;2.892460e-13&lt;/td&gt;
      &lt;td&gt;7.944669&lt;/td&gt;
      &lt;td&gt;2844.030846&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-02-01&lt;/th&gt;
      &lt;td&gt;27.130799&lt;/td&gt;
      &lt;td&gt;-1.351069e-17&lt;/td&gt;
      &lt;td&gt;-407905.660648&lt;/td&gt;
      &lt;td&gt;2.892460e-13&lt;/td&gt;
      &lt;td&gt;7.908482&lt;/td&gt;
      &lt;td&gt;3618.747348&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-03-01&lt;/th&gt;
      &lt;td&gt;27.130799&lt;/td&gt;
      &lt;td&gt;-1.351069e-17&lt;/td&gt;
      &lt;td&gt;-407905.660648&lt;/td&gt;
      &lt;td&gt;2.892460e-13&lt;/td&gt;
      &lt;td&gt;7.875797&lt;/td&gt;
      &lt;td&gt;4318.491286&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-04-01&lt;/th&gt;
      &lt;td&gt;27.130799&lt;/td&gt;
      &lt;td&gt;-1.351069e-17&lt;/td&gt;
      &lt;td&gt;-407905.660648&lt;/td&gt;
      &lt;td&gt;2.892460e-13&lt;/td&gt;
      &lt;td&gt;7.839610&lt;/td&gt;
      &lt;td&gt;5093.207789&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-05-01&lt;/th&gt;
      &lt;td&gt;27.130799&lt;/td&gt;
      &lt;td&gt;-1.351069e-17&lt;/td&gt;
      &lt;td&gt;-407905.660648&lt;/td&gt;
      &lt;td&gt;2.892460e-13&lt;/td&gt;
      &lt;td&gt;7.804590&lt;/td&gt;
      &lt;td&gt;5842.933436&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(
    df_pred
    [[&#39;mean&#39;, &#39;mean_pred&#39;]]
    .plot(figsize=(12,5), style=[&#39;o--&#39;, &#39;--&#39;])
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./2018-03-19%20Ad%20hoc%20Big%20Data%20Analysis%20with%20Dask_34_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(
    df_pred
    [[&#39;sum&#39;, &#39;sum_pred&#39;]]
    .plot(figsize=(12,5), style=[&#39;o--&#39;, &#39;--&#39;])
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./2018-03-19%20Ad%20hoc%20Big%20Data%20Analysis%20with%20Dask_35_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
